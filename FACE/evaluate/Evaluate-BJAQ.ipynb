{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Change it to the project root path \"\"\"\n",
    "PROJECT_PATH = '../'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchquad import  enable_cuda, VEGAS\n",
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = 1\n",
    "dataset_name = 'BJAQ'\n",
    "\n",
    "\n",
    "\"\"\" network parameters \"\"\"\n",
    "hidden_features = 56\n",
    "num_flow_steps = 6\n",
    "\n",
    "flow_id = 1\n",
    "\n",
    "features = 5\n",
    "\n",
    "REUSE_FROM_FILE = False\n",
    "REUSE_FILE_PATH = PROJECT_PATH + 'train/'\n",
    "\n",
    "\n",
    "\"\"\" query settings\"\"\"\n",
    "query_seed = 45     \n",
    "QUERY_CNT = 2000\n",
    "\n",
    "\"\"\" detailed network parameters\"\"\"\n",
    "anneal_learning_rate = True\n",
    "base_transform_type = 'rq-coupling'\n",
    "\n",
    "dropout_probability = 0\n",
    "grad_norm_clip_value = 5.\n",
    "linear_transform_type='lu'\n",
    "\n",
    "num_bins = 8\n",
    "num_training_steps = 400000\n",
    "num_transform_blocks = 2\n",
    "seed = 1638128\n",
    "tail_bound = 3\n",
    "use_batch_norm = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE NAME\n",
      " Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, sys\n",
    "\n",
    "\"\"\" set GPU first \"\"\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(GPU_ID)\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from time import sleep\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from nflows import transforms\n",
    "from nflows import distributions\n",
    "from nflows import utils\n",
    "from nflows import flows\n",
    "import nflows.nn as nn_\n",
    "\n",
    "\n",
    "\n",
    "import dataUtils as ut\n",
    "\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "DEVICENAME = torch.cuda.get_device_name(0)\n",
    "print('DEVICE NAME\\n', DEVICENAME)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Construction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_transform():\n",
    "    if linear_transform_type == 'permutation':\n",
    "        return transforms.RandomPermutation(features=features)\n",
    "    elif linear_transform_type == 'lu':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.LULinear(features, identity_init=True)\n",
    "        ])\n",
    "    elif linear_transform_type == 'svd':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.SVDLinear(features, num_householder=10, identity_init=True)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def create_base_transform(i):\n",
    "    # tmp_mask = utils.create_alternating_binary_mask(features, even=(i % 2 == 0))\n",
    "    return transforms.coupling.PiecewiseRationalQuadraticCouplingTransform(\n",
    "        mask=utils.create_alternating_binary_mask(features, even=(i % 2 == 0)),\n",
    "        transform_net_create_fn=lambda in_features, out_features: nn_.nets.ResidualNet(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            hidden_features=hidden_features,\n",
    "            context_features=None,\n",
    "            num_blocks=num_transform_blocks,\n",
    "            activation=F.relu,\n",
    "            dropout_probability=dropout_probability,\n",
    "            use_batch_norm=use_batch_norm\n",
    "        ),\n",
    "        num_bins=num_bins,\n",
    "        tails='linear',\n",
    "        tail_bound=tail_bound,\n",
    "        apply_unconditional_transform=True\n",
    "    )\n",
    "\n",
    "\n",
    "# torch.masked_select()\n",
    "def create_transform():\n",
    "    transform = transforms.CompositeTransform([\n",
    "        transforms.CompositeTransform([\n",
    "            create_linear_transform(),\n",
    "            create_base_transform(i)\n",
    "        ]) for i in range(num_flow_steps)\n",
    "    ] + [\n",
    "        create_linear_transform()\n",
    "    ])\n",
    "    return transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 98004 trainable parameters in this model.\n",
      "Parameters total size is 0.3738555908203125 MB\n"
     ]
    }
   ],
   "source": [
    "distribution = distributions.StandardNormal((features,))\n",
    "transform = create_transform()\n",
    "flow = flows.Flow(transform, distribution).to(device)\n",
    "model_name='BJAQ'\n",
    "\n",
    "# if 'Ti' in DEVICENAME:\n",
    "#     path = os.path.join(PROJECT_PATH+'train/models/{}'.format(dataset_name),\n",
    "#                         '{}-id{}-best-val.t'.format(dataset_name, flow_id))\n",
    "\n",
    "# else:\n",
    "#     assert False\n",
    "\n",
    "path = os.path.join(PROJECT_PATH+'train/models/{}'.format(model_name),\n",
    "                        '{}-id{}-best-val.t'.format(model_name, flow_id))\n",
    "\n",
    "flow.load_state_dict(torch.load(path))\n",
    "\n",
    "flow.cuda()\n",
    "flow.eval()\n",
    "\n",
    "\n",
    "n_params = utils.get_num_parameters(flow)\n",
    "print('There are {} trainable parameters in this model.'.format(n_params))\n",
    "print('Parameters total size is {} MB'.format(n_params * 4 / 1024 / 1024))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DataWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (300000, 5)\n"
     ]
    }
   ],
   "source": [
    "data, n, dim = ut.LoadTable(dataset_name)\n",
    "DW = ut.DataWrapper(data, dataset_name)\n",
    "rng = np.random.RandomState(query_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save oracle results to :\n",
      "../evaluate/oracle/BJAQ_rng-45.csv\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(query_seed)\n",
    "queries = DW.generateNQuery(2000, rng)\n",
    "DW.getAndSaveOracle(queries, query_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found oracle card!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Load oracle_cards\"\"\"\n",
    "oracle_cards = ut.LoadOracleCardinalities(dataset_name, query_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_lists = DW.getLegalRangeNQuery(queries)\n",
    "legal_tensors = torch.Tensor(legal_lists).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchquad import set_up_backend\n",
    "set_up_backend(\"torch\", data_type=\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" q-error \"\"\"\n",
    "def ErrorMetric(est_card, card):\n",
    "    if isinstance(est_card, torch.FloatTensor) or isinstance(est_card, torch.IntTensor):\n",
    "        est_card = est_card.cpu().detach().numpy()\n",
    "    if isinstance(est_card, torch.Tensor):\n",
    "        est_card = est_card.cpu().detach().numpy()\n",
    "    est_card = np.float32(est_card)\n",
    "    card = np.float32(card)\n",
    "    if card == 0 and est_card != 0:\n",
    "        return est_card\n",
    "    if card != 0 and est_card == 0:\n",
    "        return card\n",
    "    if card == 0 and est_card == 0:\n",
    "        return 1.0\n",
    "    return max(est_card / card, card / est_card)\n",
    "\n",
    "def BatchErrorMetrix(est_list, oracle_list):\n",
    "    ret = np.zeros(len(est_list))\n",
    "    ID = 0\n",
    "    for est, real in zip(est_list, oracle_list):\n",
    "        ret[ID] = ErrorMetric(est, real)\n",
    "        ID = ID + 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_batch_time = 0\n",
    "def f_batch(inp):\n",
    "    global f_batch_time\n",
    "    with torch.no_grad():\n",
    "        inp = inp.cuda()\n",
    "\n",
    "        print(\"【Example input】\", inp[0,:])\n",
    "        print(\"inp shape \", inp.shape)\n",
    "        st = time.time()\n",
    "        prob_list = flow.log_prob(inp)\n",
    "        prob_list = torch.exp(prob_list)\n",
    "        print(\"【max_prob】 \",prob_list.max())\n",
    "        print(\"【median_prob】 \",prob_list.median())\n",
    "        en = time.time()\n",
    "        f_batch_time += en - st\n",
    "\n",
    "        return prob_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    def __init__(self, activated=True):\n",
    "        self.activated = activated\n",
    "        self.original_stdout = None\n",
    "\n",
    "    def open(self):\n",
    "        \"\"\" no output \"\"\"\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self.original_stdout\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\" output \"\"\"\n",
    "        self.original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __enter__(self):\n",
    "        if self.activated:\n",
    "            self.close()\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.activated:\n",
    "            self.open()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse Sampling Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# f=open('/home/jiayi/disk/FACE/map.pickle','wb')  \n",
    "# pickle.dump(target_map, f)\n",
    "if REUSE_FROM_FILE == True:\n",
    "    f=open(REUSE_FILE_PATH + '{}.pickle'.format(dataset_name),'rb')  \n",
    "    target_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "z = DW.getLegalRangeQuery([[],[],[]])\n",
    "z = torch.Tensor(z)\n",
    "print(z.shape)\n",
    "full_integration_domain = torch.Tensor(z)\n",
    "\n",
    "domain_starts = full_integration_domain[:, 0]\n",
    "domain_sizes =  full_integration_domain[:, 1] - domain_starts\n",
    "domain_volume = torch.prod(domain_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【Example input】 tensor([-0.6505, -0.0268,  3.8398,  5.0084,  1.4060])\n",
      "inp shape  torch.Size([177777, 5])\n",
      "【max_prob】  tensor(0.3086)\n",
      "【median_prob】  tensor(5.3106e-22)\n",
      "******** ANY\n",
      "【Example input】 tensor([ 5.2280,  9.1315,  2.4921,  1.6087, -0.8767])\n",
      "inp shape  torch.Size([177777, 5])\n",
      "【max_prob】  tensor(0.1773)\n",
      "【median_prob】  tensor(1.6700e-19)\n",
      "******** ANY\n",
      "【Example input】 tensor([ 4.1837, -0.9271,  5.8035, -0.5073,  0.0949])\n",
      "inp shape  torch.Size([177777, 5])\n",
      "【max_prob】  tensor(1.1549)\n",
      "【median_prob】  tensor(1.2626e-17)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.4788,  7.1212,  1.3474,  1.0277,  1.6103])\n",
      "inp shape  torch.Size([177777, 5])\n",
      "【max_prob】  tensor(3.5428)\n",
      "【median_prob】  tensor(5.9806e-16)\n",
      "******** ANY\n",
      "【Example input】 tensor([ 0.9529, -0.2215,  0.6464, 13.7346, -2.5447])\n",
      "inp shape  torch.Size([177777, 5])\n",
      "【max_prob】  tensor(0.7428)\n",
      "【median_prob】  tensor(1.6268e-14)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.9186, -0.4937, -0.9970, -0.9143, -2.0902])\n",
      "inp shape  torch.Size([805255, 5])\n",
      "【max_prob】  tensor(5.5236)\n",
      "【median_prob】  tensor(4.6116e-13)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.5442, -0.3343, -1.0019, -1.0132, -2.2809])\n",
      "inp shape  torch.Size([1203193, 5])\n",
      "【max_prob】  tensor(27.3672)\n",
      "【median_prob】  tensor(0.0021)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.9675, -0.5498, -1.1642, -0.9874, -2.0725])\n",
      "inp shape  torch.Size([1205599, 5])\n",
      "【max_prob】  tensor(80.5699)\n",
      "【median_prob】  tensor(0.0116)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.8041, -0.7039, -1.3847, -1.0200, -1.5355])\n",
      "inp shape  torch.Size([1203746, 5])\n",
      "【max_prob】  tensor(74.9574)\n",
      "【median_prob】  tensor(0.0181)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.7891, -0.7527, -1.1581, -0.9705, -2.7207])\n",
      "inp shape  torch.Size([1199527, 5])\n",
      "【max_prob】  tensor(106.6653)\n",
      "【median_prob】  tensor(0.0147)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.8769, -0.8989, -1.1756, -0.8626, -1.5181])\n",
      "inp shape  torch.Size([2082373, 5])\n",
      "【max_prob】  tensor(138.3135)\n",
      "【median_prob】  tensor(0.0144)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.9044, -1.1022, -1.2058, -0.9742, -1.5411])\n",
      "inp shape  torch.Size([2078023, 5])\n",
      "【max_prob】  tensor(118.6290)\n",
      "【median_prob】  tensor(0.0131)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.8751, -0.9079, -1.3134, -0.8459, -2.7577])\n",
      "inp shape  torch.Size([2076408, 5])\n",
      "【max_prob】  tensor(107.3856)\n",
      "【median_prob】  tensor(0.0114)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.8916, -0.8850, -1.3856, -0.9205, -2.0268])\n",
      "inp shape  torch.Size([2075910, 5])\n",
      "【max_prob】  tensor(148.2507)\n",
      "【median_prob】  tensor(0.0092)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.8983, -1.0748, -1.2080, -0.8993, -1.8519])\n",
      "inp shape  torch.Size([2075446, 5])\n",
      "【max_prob】  tensor(109.7148)\n",
      "【median_prob】  tensor(0.0082)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.8935, -1.0230, -1.1655, -0.8874, -1.8886])\n",
      "inp shape  torch.Size([2961472, 5])\n",
      "【max_prob】  tensor(141.8149)\n",
      "【median_prob】  tensor(0.0092)\n",
      "【Example input】 tensor([-0.9535, -1.0958, -1.3717, -0.9067, -1.5604])\n",
      "inp shape  torch.Size([2960220, 5])\n",
      "【max_prob】  tensor(184.2499)\n",
      "【median_prob】  tensor(0.0108)\n",
      "【Example input】 tensor([-0.9456, -1.0902, -1.1790, -0.9688, -1.7646])\n",
      "inp shape  torch.Size([2959929, 5])\n",
      "【max_prob】  tensor(168.3264)\n",
      "【median_prob】  tensor(0.0085)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.9572, -0.9330, -1.3491, -0.9563, -1.8929])\n",
      "inp shape  torch.Size([2959522, 5])\n",
      "【max_prob】  tensor(130.2350)\n",
      "【median_prob】  tensor(0.0094)\n",
      "******** ANY\n",
      "【Example input】 tensor([-0.9532, -1.0014, -1.2134, -0.9795, -1.6345])\n",
      "inp shape  torch.Size([2958970, 5])\n",
      "【max_prob】  tensor(136.0416)\n",
      "【median_prob】  tensor(0.0094)\n",
      "******** ANY\n",
      "Took  7.097137212753296\n",
      "tensor(0.9940)\n",
      "result is  tensor(298198.5000)\n"
     ]
    }
   ],
   "source": [
    "if REUSE_FROM_FILE == False:\n",
    "    vegas = VEGAS()\n",
    "    bigN = 1000000 * 40\n",
    "\n",
    "    st = time.time()\n",
    "    result = vegas.integrate(f_batch,dim=features,\n",
    "                             N=bigN,\n",
    "                             integration_domain=full_integration_domain,\n",
    "                             use_warmup=True,\n",
    "                             use_grid_improve=True,\n",
    "                             max_iterations=40\n",
    "                             )\n",
    "\n",
    "    en= time.time()\n",
    "    print(\"Took \", en-st)\n",
    "    print(result)\n",
    "    result = result * DW.n\n",
    "\n",
    "    print('result is ',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REUSE_FROM_FILE == False:\n",
    "    target_map = vegas.map\n",
    "    import pickle\n",
    "    f=open(REUSE_FILE_PATH + \"{}.pickle\".format(dataset_name),'wb')  \n",
    "    pickle.dump(target_map, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchquad import BatchMulVEGAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResult(n, N, num_iterations=3, alpha=0.5, beta=0.5):\n",
    "    global f_batch_time\n",
    "    \"\"\" n: batch size \"\"\"\n",
    "    z = BatchMulVEGAS()\n",
    "    DIM = features\n",
    "    full_integration_domain = torch.Tensor(DIM * [[0,1]])\n",
    "    \n",
    "    start_id = 0\n",
    "    end_id = 0\n",
    "\n",
    "    f_batch_time  = 0\n",
    "    st = time.time()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        while start_id < 2000:\n",
    "            end_id = end_id + n\n",
    "            if end_id > 2000:\n",
    "                end_id = 2000\n",
    "            z.setValues(f_batch,\n",
    "                    dim=DIM,\n",
    "                    alpha=alpha,\n",
    "                    beta=beta,\n",
    "                    N=N,\n",
    "                    n=end_id - start_id,\n",
    "                    iterations=num_iterations,\n",
    "                    integration_domains=legal_tensors[start_id:end_id],\n",
    "                    rng=None,\n",
    "                    seed=1234,\n",
    "                    reuse_sample_points=True,\n",
    "                    target_map=target_map,\n",
    "                    target_domain_starts = domain_starts,\n",
    "                    target_domain_sizes = domain_sizes,\n",
    "                    )\n",
    "            start_id = start_id + n\n",
    "            results.append(z.integrate())\n",
    "\n",
    "    en = time.time()\n",
    "    total_time = en-st\n",
    "    return total_time, results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### end-to-end function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testHyper(n, N, num_iterations, alpha, beta):\n",
    "    with HiddenPrints():\n",
    "        total_time, result = getResult(n=n, \n",
    "                               N=N, \n",
    "                               num_iterations=num_iterations,\n",
    "                               alpha=alpha, \n",
    "                               beta=beta)\n",
    "    \n",
    "\n",
    "        result = torch.cat(tuple(result))\n",
    "        FULL_SIZE = torch.Tensor([DW.n])\n",
    "        result = result * FULL_SIZE\n",
    "        result = result.to('cpu')\n",
    "\n",
    "        n_ = 2000\n",
    "        oracle_list = oracle_cards.copy()\n",
    "\n",
    "        err_list = BatchErrorMetrix(result.int(), oracle_list)\n",
    "\n",
    "\n",
    "        total_query_time = total_time\n",
    "        avg_per_query_time = 1000. * (total_query_time/n_)\n",
    "        avg_f_batch_time   = 1000.* f_batch_time / n_\n",
    "        avg_vegas_time     = avg_per_query_time - avg_f_batch_time\n",
    "\n",
    "\n",
    "\n",
    "    print(\"********** total_n=[{}] batchn=[{}]  N=[{}]  nitr=[{}]  alpha=[{}]  beta=[{}] ******\".format(n_, n, N, num_iterations, alpha, beta))\n",
    "    print('@ Average per query          [{}] ms'.format(avg_per_query_time))\n",
    "    print(' --  Average per query NF    [{}] ms'.format(avg_f_batch_time))\n",
    "    print(' --  Average per query vegas [{}] ms'.format(avg_vegas_time))\n",
    "    p50 = np.percentile (err_list, 50)\n",
    "    mean = np.mean (err_list) \n",
    "    p95 = np.percentile(err_list, 95)\n",
    "    p99 = np.percentile(err_list, 99)\n",
    "    pmax = np.max(err_list)\n",
    "    print('Mean [{:.3f}]  Median [{:.3f}]  95th [{:.3f}]  99th [{:.3f}]  max [{:.3f}]'.format(mean, p50, p95,\n",
    "                                                               p99, pmax))\n",
    "\n",
    "    return p50,p95,p99,pmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** total_n=[2000] batchn=[1000]  N=[16000]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******\n",
      "@ Average per query          [5.348286986351013] ms\n",
      " --  Average per query NF    [3.5182876586914062] ms\n",
      " --  Average per query vegas [1.829999327659607] ms\n",
      "Mean [236.604]  Median [1.535]  95th [59.468]  99th [10100.505]  max [20003.000]\n"
     ]
    }
   ],
   "source": [
    "alpha_list= [0.4]\n",
    "beta_list = [0.2]\n",
    "\n",
    "p50s = []\n",
    "p95s = []\n",
    "p99s = []\n",
    "pmaxs = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    for beta in beta_list:\n",
    "        p50, p95, p99, pmax = testHyper(1000, 16000, 4, alpha, beta)\n",
    "        p50s.append(p50)\n",
    "        p95s.append(p95)\n",
    "        p99s.append(p99s)\n",
    "        pmaxs.append(pmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
